{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metal Puzzles\n",
    "\n",
    "Port of [srush/GPU-Puzzles](https://github.com/srush/GPU-Puzzles) to [Metal](https://en.wikipedia.org/wiki/Metal_API) using [MLX Custom Kernels](https://ml-explore.github.io/mlx/build/html/dev/custom_metal_kernels.html). Inspired by [@awnihannun](https://x.com/awnihannun/status/1833376670063202536)!\n",
    "\n",
    "![Metal Puzzles Logo](./imgs/metal_puzzles.png)\n",
    "\n",
    "GPUs are crucial in machine learning because they can process data on a massively parallel scale. While it's possible to become an expert in machine learning without writing any GPU code, building intuition is challenging when you're only working through layers of abstraction. Additionally, as models grow in complexity, the need for developers to write efficient, high-performance kernels becomes increasingly important to leverage the power of modern hardware.\n",
    "\n",
    "Whether you're new to GPU programming or have experience with CUDA, the following puzzles provide a straightforward way to learn on an Apple Silicon computer. In the following exercises, you'll use the `mx.fast.metal_kernel()` function from Apple's [mlx](https://github.com/ml-explore/mlx) framework, which allows you to write custom Metal kernels through a Python/C++ API. For verification purposes, I've created a wrapper class around `mx.fast.metal_kernel()` called `MetalKernel`, but the interface remains identical.\n",
    "\n",
    "If you're interested in more material, check out the [MLX Custom Metal Kernels Documentation](https://ml-explore.github.io/mlx/build/html/dev/custom_metal_kernels.html) and the [Metal Shading Language specification](https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "from utils import MetalKernel, MetalProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['VERBOSE'] = '1'\n",
    "os.environ['MLT_CAPTURE_ENABLED'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 1: Map\n",
    "\n",
    "Implement a \"kernel\" (GPU function) that adds 10 to each position of the array `a` and stores it in the array `out`.  You have 1 thread per position.\n",
    "\n",
    "**Note:** The `source` string below is the body of your Metal kernel, the function signature will be automatically generated for you. Below you'll notice the `input_names` and `output_names` parameters. These define the parameters for your Metal kernel.\n",
    "\n",
    "**Tip:** If you need a tool for debugging your Kernel read the *Metal Debugger* section at the bottom of the README. Also, you can print out the generated Metal kernel by setting the environment variable `VERBOSE=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Map\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             1 |             1 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def map_spec(a: mx.array):\n",
    "    return a + 10\n",
    "\n",
    "def map_test(a: mx.array):\n",
    "    source = \"\"\"\n",
    "        uint local_i = thread_position_in_grid.x;\n",
    "        out[local_i] = a[local_i] + 10;\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"map\",\n",
    "        input_names=[\"a\"],\n",
    "        output_names=[\"out\"],\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 4\n",
    "a = mx.arange(SIZE)\n",
    "output_shape = (SIZE,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Map\",\n",
    "    map_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(SIZE,1,1), \n",
    "    spec=map_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated source code for `map`:\n",
      "```\n",
      "\n",
      "[[kernel]] void custom_kernel_map(\n",
      "  const device int32_t* a [[buffer(0)]],\n",
      "  device float* out [[buffer(1)]],\n",
      "  uint3 thread_position_in_grid [[thread_position_in_grid]]) {\n",
      "\n",
      "        uint local_i = thread_position_in_grid.x;\n",
      "        out[local_i] = a[local_i] + 10;\n",
      "    \n",
      "}\n",
      "\n",
      "```\n",
      "Passed Tests!\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 2: Zip \n",
    "\n",
    "Implement a kernel that takes two arrays `a` and `b`, adds each element together, and stores the result in the output array `out`. You have 1 thread per position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Zip\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             2 |             1 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def zip_spec(a: mx.array, b: mx.array):\n",
    "    return a + b\n",
    "\n",
    "def zip_test(a: mx.array, b: mx.array):\n",
    "    source = \"\"\"\n",
    "        uint local_i = thread_position_in_grid.x;\n",
    "        out[local_i] = a[local_i] + b[local_i];\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"zip\",\n",
    "        input_names=[\"a\", \"b\"],\n",
    "        output_names=[\"out\"],\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 4\n",
    "a = mx.arange(SIZE)\n",
    "b = mx.arange(SIZE)\n",
    "output_shapes = (SIZE,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Zip\",\n",
    "    zip_test,\n",
    "    [a, b],\n",
    "    output_shapes,\n",
    "    grid=(SIZE,1,1),\n",
    "    spec=zip_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated source code for `zip`:\n",
      "```\n",
      "\n",
      "[[kernel]] void custom_kernel_zip(\n",
      "  const device int32_t* a [[buffer(0)]],\n",
      "  const device int32_t* b [[buffer(1)]],\n",
      "  device float* out [[buffer(2)]],\n",
      "  uint3 thread_position_in_grid [[thread_position_in_grid]]) {\n",
      "\n",
      "        uint local_i = thread_position_in_grid.x;\n",
      "        out[local_i] = a[local_i] + b[local_i];\n",
      "    \n",
      "}\n",
      "\n",
      "```\n",
      "Passed Tests!\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 3: Guard\n",
    "\n",
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`. You have more threads than positions.\n",
    "\n",
    "**Warning:** Be careful of out-of-bounds access.\n",
    "\n",
    "**Note:** You can append `_shape`, `_strides`, or `_ndim` to any input parameter to automatically add that data as a paramter to your kerenls. So, in the following puzzle you could use `a_shape`, `a_strides`, or `a_ndim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Guard\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             1 |             1 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def map_guard_test(a: mx.array):\n",
    "    source = \"\"\"\n",
    "        uint local_i = thread_position_in_grid.x;\n",
    "        uint a_bound = a_shape[0];\n",
    "        if (local_i < a_bound) {\n",
    "            out[local_i] = a[local_i] + 10;\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"guard\",\n",
    "        input_names=[\"a\"],\n",
    "        output_names=[\"out\"],\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 4\n",
    "a = mx.arange(SIZE)\n",
    "output_shape = (SIZE,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Guard\",\n",
    "    map_guard_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(8,1,1), \n",
    "    spec=map_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated source code for `guard`:\n",
      "```\n",
      "\n",
      "[[kernel]] void custom_kernel_guard(\n",
      "  const device int32_t* a [[buffer(0)]],\n",
      "  const constant int* a_shape [[buffer(1)]],\n",
      "  device float* out [[buffer(2)]],\n",
      "  uint3 thread_position_in_grid [[thread_position_in_grid]]) {\n",
      "\n",
      "        uint local_i = thread_position_in_grid.x;\n",
      "        uint a_bound = a_shape[0];\n",
      "        if (local_i < a_bound) {\n",
      "            out[local_i] = a[local_i] + 10;\n",
      "        }\n",
      "    \n",
      "}\n",
      "\n",
      "```\n",
      "Passed Tests!\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 4: Map 2D\n",
    "\n",
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`. Input `a` is 2D and square. You have more threads than positions.\n",
    "\n",
    "**Note:** All memory in Metal is represented as a 1D array, so direct 2D indexing is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Map 2D\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             1 |             1 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def map_2D_test(a: mx.array):\n",
    "    source = \"\"\"\n",
    "        uint thread_x = thread_position_in_grid.x;\n",
    "        uint thread_y = thread_position_in_grid.y;\n",
    "        uint H = a_shape[0];\n",
    "        uint W = a_shape[1];\n",
    "        if (thread_x < H && thread_y < W) {\n",
    "            out[thread_x + H * thread_y] = a[thread_x + H * thread_y] + 10; \n",
    "        }\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"map_2D\",\n",
    "        input_names=[\"a\"],\n",
    "        output_names=[\"out\"],\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 2\n",
    "a = mx.arange(SIZE * SIZE).reshape((SIZE, SIZE))\n",
    "output_shape = (SIZE, SIZE)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Map 2D\",\n",
    "    map_2D_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(3,3,1), \n",
    "    spec=map_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated source code for `map_2D`:\n",
      "```\n",
      "\n",
      "[[kernel]] void custom_kernel_map_2D(\n",
      "  const device int32_t* a [[buffer(0)]],\n",
      "  const constant int* a_shape [[buffer(1)]],\n",
      "  device float* out [[buffer(2)]],\n",
      "  uint3 thread_position_in_grid [[thread_position_in_grid]]) {\n",
      "\n",
      "        uint thread_x = thread_position_in_grid.x;\n",
      "        uint thread_y = thread_position_in_grid.y;\n",
      "        uint H = a_shape[0];\n",
      "        uint W = a_shape[1];\n",
      "        if (thread_x < H && thread_y < W) {\n",
      "            out[thread_x + H * thread_y] = a[thread_x + H * thread_y] + 10; \n",
      "        }\n",
      "        \n",
      "    \n",
      "}\n",
      "\n",
      "```\n",
      "Passed Tests!\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 5: Broadcast\n",
    "\n",
    "Implement a kernel that adds `a` and `b` and stores it in `out`. Inputs `a` and `b` are arrays. You have more threads than positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Broadcast\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def broadcast_test(a: mx.array, b: mx.array):\n",
    "    source = \"\"\"\n",
    "        uint thread_x = thread_position_in_grid.x;\n",
    "        uint thread_y = thread_position_in_grid.y;\n",
    "        // FILL ME IN (roughly 4 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"broadcast\",\n",
    "        input_names=[\"a\", \"b\"],\n",
    "        output_names=[\"out\"],\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 2\n",
    "a = mx.arange(SIZE).reshape(SIZE, 1)\n",
    "b = mx.arange(SIZE).reshape(1, SIZE)\n",
    "output_shape = (SIZE, SIZE)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Broadcast\",\n",
    "    broadcast_test,\n",
    "    [a, b], \n",
    "    output_shape,\n",
    "    grid=(3,3,1), \n",
    "    spec=zip_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([[0, 0],\n",
      "       [0, 0]], dtype=float32)\n",
      "Spec : array([[0, 1],\n",
      "       [1, 2]], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 6: Threadgroups\n",
    "\n",
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`. You have fewer threads per threadgroup than the size of `a`, but more threads than positions.\n",
    "\n",
    "**Note:** A threadgroup is simply a group of threads within the thread grid. The number of threads per threadgroup is limited to a defined number, but we can have multiple different threadgroups. The Metal parameter `threadgroup_position_in_grid` tells us what threadgroup we are in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Threadgroups\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def map_threadgroup_test(a: mx.array):\n",
    "    source = \"\"\"\n",
    "        uint i = threadgroup_position_in_grid.x * threads_per_threadgroup.x + thread_position_in_threadgroup.x;\n",
    "        // FILL ME IN (roughly 1-3 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"threadgroups\",\n",
    "        input_names=[\"a\"],\n",
    "        output_names=[\"out\"],\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 9\n",
    "a = mx.arange(SIZE)\n",
    "output_shape = (SIZE,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Threadgroups\",\n",
    "    map_threadgroup_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(12,1,1), \n",
    "    threadgroup=(4,1,1),\n",
    "    spec=map_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([0, 0, 0, ..., 0, 0, 0], dtype=float32)\n",
      "Spec : array([10, 11, 12, ..., 16, 17, 18], dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 7: Threadgroups 2D\n",
    "\n",
    "Implement the same kernel in 2D. You have fewer threads per threadgroup than the size of `a` in both directions, but more threads than positions in the grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Threadgroups 2D\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def map_threadgroup_2D_test(a: mx.array):\n",
    "    source = \"\"\"\n",
    "        uint i = threadgroup_position_in_grid.x * threads_per_threadgroup.x + thread_position_in_threadgroup.x;\n",
    "        // FILL ME IN (roughly 5 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"threadgroups_2D\",\n",
    "        input_names=[\"a\"],\n",
    "        output_names=[\"out\"],\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 5\n",
    "a = mx.ones((SIZE, SIZE))\n",
    "output_shape = (SIZE, SIZE)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Threadgroups 2D\",\n",
    "    map_threadgroup_2D_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(6,6,1), \n",
    "    threadgroup=(3,3,1),\n",
    "    spec=map_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([[0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0]], dtype=float32)\n",
      "Spec : array([[11, 11, 11, 11, 11],\n",
      "       [11, 11, 11, 11, 11],\n",
      "       [11, 11, 11, 11, 11],\n",
      "       [11, 11, 11, 11, 11],\n",
      "       [11, 11, 11, 11, 11]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 8: Threadgroup Memory\n",
    "\n",
    "Implement a kernel that adds 10 to each position of `a` and stores it in `out`. You have fewer threads per threadgroup than the size of `a`.\n",
    "\n",
    "**Warning**: Each threadgroup can only have a *constant* amount of threadgroup memory that the threads can read and write to. After writing to threadgroup memory, you need to call `threadgroup_barrier(mem_flags::mem_threadgroup)` to ensure that threads are synchronized. In this puzzle we add the `header` variable as a new parameter to the `MetalKernel` object, which simply defines values outside of the kernel body (often used for header imports).\n",
    "\n",
    "For more information read section [4.4 Threadgroup Address Space](https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf#page=86) and section [6.9 Synchronization and SIMD-Group Functions](https://developer.apple.com/metal/Metal-Shading-Language-Specification.pdf#page=177) in the Metal Shading Language Specification.\n",
    "\n",
    "(This example does not really need threadgroup memory or synchronization, but it's a demo.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Threadgroup Memory\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             1 |             0 |             0 |             1 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def shared_test(a: mx.array):\n",
    "    header = \"\"\"\n",
    "        constant uint THREADGROUP_MEM_SIZE = 4;\n",
    "    \"\"\"\n",
    "\n",
    "    source = \"\"\"\n",
    "        threadgroup float shared[THREADGROUP_MEM_SIZE];\n",
    "        uint i = threadgroup_position_in_grid.x * threads_per_threadgroup.x + thread_position_in_threadgroup.x;\n",
    "        uint local_i = thread_position_in_threadgroup.x;\n",
    "\n",
    "        if (i < a_shape[0]) {\n",
    "            shared[local_i] = a[i];\n",
    "            threadgroup_barrier(mem_flags::mem_threadgroup);\n",
    "        }\n",
    "\n",
    "        // FILL ME IN (roughly 1-3 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"threadgroup_memory\",\n",
    "        input_names=[\"a\"],\n",
    "        output_names=[\"out\"],\n",
    "        header=header,\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 8\n",
    "a = mx.ones(SIZE)\n",
    "output_shape = (SIZE,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Threadgroup Memory\",\n",
    "    shared_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(SIZE,1,1), \n",
    "    threadgroup=(4,1,1),\n",
    "    spec=map_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([0, 0, 0, ..., 0, 0, 0], dtype=float32)\n",
      "Spec : array([11, 11, 11, ..., 11, 11, 11], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 9: Pooling\n",
    "\n",
    "Implement a kernel that sums together the last 3 position of `a` and stores it in `out`. You have 1 thread per position. \n",
    "\n",
    "**Note:** `threadgroup` memory is often faster than sharing data in `device` memory because it is located closer the the GPU's compute units. Be careful of uncessary reads and writes from global parameters (`a` and `out`), since their data is stored in `device` memory. You only need 1 global read and 1 global write per thread.\n",
    "\n",
    "**Tip:** Remember to be careful about syncing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Pooling\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def pooling_spec(a: mx.array):\n",
    "    out = mx.zeros(*a.shape)\n",
    "    for i in range(a.shape[0]):\n",
    "        out[i] = a[max(i - 2, 0) : i + 1].sum()\n",
    "    return out\n",
    "\n",
    "def pooling_test(a: mx.array):\n",
    "    header = \"\"\"\n",
    "        constant uint THREADGROUP_MEM_SIZE = 8;\n",
    "    \"\"\"\n",
    "\n",
    "    source = \"\"\"\n",
    "        threadgroup float shared[THREADGROUP_MEM_SIZE];\n",
    "        uint i = threadgroup_position_in_grid.x * threads_per_threadgroup.x + thread_position_in_threadgroup.x;\n",
    "        uint local_i = thread_position_in_threadgroup.x;\n",
    "        // FILL ME IN (roughly 11 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"pooling\",\n",
    "        input_names=[\"a\"],\n",
    "        output_names=[\"out\"],\n",
    "        header=header,\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 8\n",
    "a = mx.arange(SIZE)\n",
    "output_shape = (SIZE,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Pooling\",\n",
    "    pooling_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(SIZE,1,1), \n",
    "    threadgroup=(SIZE,1,1),\n",
    "    spec=pooling_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([0, 0, 0, ..., 0, 0, 0], dtype=float32)\n",
      "Spec : array([0, 1, 3, ..., 12, 15, 18], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 10: Dot Product\n",
    "\n",
    "Implement a kernel that computes the [dot product](https://en.wikipedia.org/wiki/Dot_product#Coordinate_definition) of `a` and `b` and stores it in `out`. You have 1 thread per position. You only need 2 global reads and 1 global write per thread.\n",
    "\n",
    "**Note**: For this problem you don't need to worry about number of reads to the `threadgroup` memory. We will handle that challenge later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Dot Product\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def dot_spec(a: mx.array, b: mx.array):\n",
    "    return a @ b\n",
    "\n",
    "def dot_test(a: mx.array, b: mx.array):\n",
    "    header = \"\"\"\n",
    "        constant uint THREADGROUP_MEM_SIZE = 8;\n",
    "    \"\"\"\n",
    "\n",
    "    source = \"\"\"\n",
    "        threadgroup float shared[THREADGROUP_MEM_SIZE];\n",
    "        uint i = threadgroup_position_in_grid.x * threads_per_threadgroup.x + thread_position_in_threadgroup.x;\n",
    "        uint local_i = thread_position_in_threadgroup.x;\n",
    "        // FILL ME IN (roughly 11 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"dot_product\",\n",
    "        input_names=[\"a\", \"b\"],\n",
    "        output_names=[\"out\"],\n",
    "        header=header,\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "SIZE = 8\n",
    "a = mx.arange(SIZE, dtype=mx.float32)\n",
    "b = mx.arange(SIZE, dtype=mx.float32)\n",
    "output_shape = (1,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Dot Product\",\n",
    "    dot_test,\n",
    "    [a, b], \n",
    "    output_shape,\n",
    "    grid=(SIZE,1,1), \n",
    "    threadgroup=(SIZE,1,1),\n",
    "    spec=dot_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([0], dtype=float32)\n",
      "Spec : array(140, dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 11: 1D Convolution\n",
    "\n",
    "Implement a kernel that computes a 1D convolution between `a` and `b` and stores it in `out`. You need to handle the general case. You only need 2 global reads and 1 global write per thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1D Conv (Simple)\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def conv_spec(a: mx.array, b: mx.array):\n",
    "    out = mx.zeros(*a.shape)\n",
    "    len = b.shape[0]\n",
    "    for i in range(a.shape[0]):\n",
    "        out[i] = sum([a[i + j] * b[j] for j in range(len) if i + j < a.shape[0]])\n",
    "    return out\n",
    "\n",
    "def conv_test(a: mx.array, b: mx.array):\n",
    "    header = \"\"\"\n",
    "        constant uint THREADGROUP_MAX_CONV_SIZE = 12;\n",
    "        constant uint MAX_CONV_SIZE = 4;\n",
    "    \"\"\"\n",
    "\n",
    "    source = \"\"\"\n",
    "        uint i = threadgroup_position_in_grid.x * threads_per_threadgroup.x + thread_position_in_threadgroup.x;\n",
    "        uint local_i = thread_position_in_threadgroup.x;\n",
    "        // FILL ME IN (roughly 24 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"1D_conv\",\n",
    "        input_names=[\"a\", \"b\"],\n",
    "        output_names=[\"out\"],\n",
    "        header=header,\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "# Test 1\n",
    "SIZE = 6\n",
    "CONV = 3\n",
    "a = mx.arange(SIZE, dtype=mx.float32)\n",
    "b = mx.arange(CONV, dtype=mx.float32)\n",
    "output_shape = (SIZE,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"1D Conv (Simple)\",\n",
    "    conv_test,\n",
    "    [a, b], \n",
    "    output_shape,\n",
    "    grid=(8,1,1), \n",
    "    threadgroup=(8,1,1),\n",
    "    spec=conv_spec\n",
    ")\n",
    "\n",
    "problem.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([0, 0, 0, 0, 0, 0], dtype=float32)\n",
      "Spec : array([5, 8, 11, 14, 5, 0], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1D Conv (Full)\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Test 2\n",
    "a = mx.arange(15, dtype=mx.float32)\n",
    "b = mx.arange(4, dtype=mx.float32)\n",
    "output_shape = (15,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"1D Conv (Full)\",\n",
    "    conv_test,\n",
    "    [a, b], \n",
    "    output_shape,\n",
    "    grid=(16,1,1), \n",
    "    threadgroup=(8,1,1),\n",
    "    spec=conv_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([0, 0, 0, ..., 0, 0, 0], dtype=float32)\n",
      "Spec : array([14, 20, 26, ..., 41, 14, 0], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 12: Prefix Sum\n",
    "\n",
    "Implement a kernel that computes a sum over `a` and stores it in `out`. If the size of `a` is greater than the threadgroup size, only store the sum of each threadgroup.\n",
    "\n",
    "We will do this using the [parallel prefix sum](https://en.wikipedia.org/wiki/Prefix_sum#Parallel_algorithms) algorithm in `threadgroup` memory. In each step, the algorithm will sum half of the remaining elements together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Prefix Sum (Simple)\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "THREADGROUP_MEM_SIZE = 8\n",
    "def prefix_sum_spec(a: mx.array):\n",
    "    out = mx.zeros((a.shape[0] + THREADGROUP_MEM_SIZE - 1) // THREADGROUP_MEM_SIZE)\n",
    "    for j, i in enumerate(range(0, a.shape[-1], THREADGROUP_MEM_SIZE)):\n",
    "        out[j] = a[i : i + THREADGROUP_MEM_SIZE].sum()\n",
    "    return out\n",
    "\n",
    "def prefix_sum_test(a: mx.array):\n",
    "    header = \"\"\"\n",
    "        constant uint THREADGROUP_MEM_SIZE = 8;\n",
    "    \"\"\"\n",
    "\n",
    "    source = \"\"\"\n",
    "        threadgroup float cache[THREADGROUP_MEM_SIZE];\n",
    "        uint i = threadgroup_position_in_grid.x * threads_per_threadgroup.x + thread_position_in_threadgroup.x;\n",
    "        uint local_i = thread_position_in_threadgroup.x;\n",
    "        // FILL ME IN (roughly 14 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"prefix_sum\",\n",
    "        input_names=[\"a\"],\n",
    "        output_names=[\"out\"],\n",
    "        header=header,\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "# Test 1\n",
    "SIZE = 8\n",
    "a = mx.arange(SIZE)\n",
    "output_shape = (1,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Prefix Sum (Simple)\",\n",
    "    prefix_sum_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(8,1,1), \n",
    "    threadgroup=(8,1,1),\n",
    "    spec=prefix_sum_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([0], dtype=float32)\n",
      "Spec : array([28], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Prefix Sum (Full)\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Test 2\n",
    "SIZE = 15\n",
    "a = mx.arange(SIZE)\n",
    "output_shape = (2,)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Prefix Sum (Full)\",\n",
    "    prefix_sum_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(16,1,1), \n",
    "    threadgroup=(8,1,1),\n",
    "    spec=prefix_sum_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([0, 0], dtype=float32)\n",
      "Spec : array([28, 77], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 13: Axis Sum\n",
    "\n",
    "Implement a kernel that computes the sum over each column in the input array `a` and stores it in `out`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Axis Sum\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "THREADGROUP_MEM_SIZE = 8\n",
    "def axis_sum_spec(a: mx.array):\n",
    "    out = mx.zeros((a.shape[0], (a.shape[1] + THREADGROUP_MEM_SIZE - 1) // THREADGROUP_MEM_SIZE))\n",
    "    for j, i in enumerate(range(0, a.shape[-1], THREADGROUP_MEM_SIZE)):\n",
    "        out[..., j] = a[..., i : i + THREADGROUP_MEM_SIZE].sum(-1)\n",
    "    return out\n",
    "\n",
    "def axis_sum_test(a: mx.array):\n",
    "    header = \"\"\"\n",
    "        constant uint THREADGROUP_MEM_SIZE = 8;\n",
    "    \"\"\"\n",
    "\n",
    "    source = \"\"\"\n",
    "        threadgroup float cache[THREADGROUP_MEM_SIZE];\n",
    "        uint i = threadgroup_position_in_grid.x * threads_per_threadgroup.x + thread_position_in_threadgroup.x;\n",
    "        uint local_i = thread_position_in_threadgroup.x;\n",
    "        uint batch = threadgroup_position_in_grid.y;\n",
    "        // FILL ME IN (roughly 16 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"axis_sum\",\n",
    "        input_names=[\"a\"],\n",
    "        output_names=[\"out\"],\n",
    "        header=header,\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "BATCH = 4\n",
    "SIZE = 6\n",
    "a = mx.arange(BATCH * SIZE).reshape((BATCH, SIZE))\n",
    "output_shape = (BATCH, 1)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Axis Sum\",\n",
    "    axis_sum_test,\n",
    "    [a], \n",
    "    output_shape,\n",
    "    grid=(8,BATCH,1), \n",
    "    threadgroup=(8,1,1),\n",
    "    spec=axis_sum_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([[0],\n",
      "       [0],\n",
      "       [0],\n",
      "       [0]], dtype=float32)\n",
      "Spec : array([[15],\n",
      "       [51],\n",
      "       [87],\n",
      "       [123]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puzzle 14: Matrix Multiply\n",
    "\n",
    "Implement a kernel that multiplies square matrices `a` and `b` and stores the result in `out`.\n",
    "\n",
    "**Tip**: The most efficient algorithm will copy a block of data into `threadgroup` memory before computing each of the individual row-column dot products. This is straightforward if the matrix fits entirely in `threadgroup` memory (start by implementing that case first). Then, modify your code to compute partial dot products and iteratively move portions of the matrix into `threadgroup` memory. You should be able to handle the hard test in 6 device memory reads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Matmul (Simple)\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "def matmul_spec(a: mx.array, b: mx.array):\n",
    "    return a @ b\n",
    "\n",
    "def matmul_test(a: mx.array, b: mx.array):\n",
    "    header = \"\"\"\n",
    "        constant uint THREADGROUP_MEM_SIZE = 3;\n",
    "    \"\"\"\n",
    "\n",
    "    source = \"\"\"\n",
    "        threadgroup float a_shared[THREADGROUP_MEM_SIZE][THREADGROUP_MEM_SIZE];\n",
    "        threadgroup float b_shared[THREADGROUP_MEM_SIZE][THREADGROUP_MEM_SIZE];\n",
    "\n",
    "        uint i = threadgroup_position_in_grid.x * threads_per_threadgroup.x + thread_position_in_threadgroup.x;\n",
    "        uint j = threadgroup_position_in_grid.y * threads_per_threadgroup.y + thread_position_in_threadgroup.y;\n",
    "\n",
    "        uint local_i = thread_position_in_threadgroup.x;\n",
    "        uint local_j = thread_position_in_threadgroup.y;\n",
    "        // FILL ME IN (roughly 19 lines)\n",
    "    \"\"\"\n",
    "\n",
    "    kernel = MetalKernel(\n",
    "        name=\"matmul\",\n",
    "        input_names=[\"a\", \"b\"],\n",
    "        output_names=[\"out\"],\n",
    "        header=header,\n",
    "        source=source,\n",
    "    )\n",
    "\n",
    "    return kernel\n",
    "\n",
    "# Test 1\n",
    "SIZE = 2\n",
    "a = mx.arange(SIZE * SIZE, dtype=mx.float32).reshape((SIZE, SIZE))\n",
    "b = mx.arange(SIZE * SIZE, dtype=mx.float32).reshape((SIZE, SIZE)).T\n",
    "output_shape = (SIZE, SIZE)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Matmul (Simple)\",\n",
    "    matmul_test,\n",
    "    [a, b], \n",
    "    output_shape,\n",
    "    grid=(3,3,1), \n",
    "    threadgroup=(3,3,1),\n",
    "    spec=matmul_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([[0, 0],\n",
      "       [0, 0]], dtype=float32)\n",
      "Spec : array([[1, 3],\n",
      "       [3, 13]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Matmul (Full)\n",
      "\n",
      "    Score (Max Per Thread):\n",
      "    |  Global Reads | Global Writes |  Shared Reads | Shared Writes |\n",
      "    |             0 |             0 |             0 |             0 | \n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Test 2\n",
    "SIZE = 8\n",
    "a = mx.arange(SIZE * SIZE, dtype=mx.float32).reshape((SIZE, SIZE))\n",
    "b = mx.arange(SIZE * SIZE, dtype=mx.float32).reshape((SIZE, SIZE)).T\n",
    "output_shape = (SIZE, SIZE)\n",
    "\n",
    "problem = MetalProblem(\n",
    "    \"Matmul (Full)\",\n",
    "    matmul_test,\n",
    "    [a, b], \n",
    "    output_shape,\n",
    "    grid=(9,9,1), \n",
    "    threadgroup=(3,3,1),\n",
    "    spec=matmul_spec\n",
    ")\n",
    "\n",
    "problem.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed Tests.\n",
      "Yours: array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=float32)\n",
      "Spec : array([[140, 364, 588, ..., 1260, 1484, 1708],\n",
      "       [364, 1100, 1836, ..., 4044, 4780, 5516],\n",
      "       [588, 1836, 3084, ..., 6828, 8076, 9324],\n",
      "       ...,\n",
      "       [1260, 4044, 6828, ..., 15180, 17964, 20748],\n",
      "       [1484, 4780, 8076, ..., 17964, 21260, 24556],\n",
      "       [1708, 5516, 9324, ..., 20748, 24556, 28364]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "problem.check()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
